# -*- coding: utf-8 -*-
"""Info Retrieval

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BSO9HpBnDrIxv3RYAjwf4t7cZLR110eA
"""

import tensorflow as tf
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator
import os
from keras.models import load_model
import wikipedia
from PIL import Image
import cv2

#!pip3 install wikipedia
#pip install keras --upgrade

#from google.colab import drive
#drive.mount('/content/drive')

model = load_model('/content/drive/My Drive/Project/landmark.h5')



size = 128,128

datagen = ImageDataGenerator()
train = datagen.flow_from_directory('/content/drive/My Drive/Project/test/',target_size=(128, 128), 
                                    color_mode = "grayscale", batch_size=16,class_mode=None)
X=train.next()

classes = model.predict_classes(X,verbose=1)

orig = datagen.flow_from_directory('/content/drive/My Drive/Project/CV Dataset/mod_data',target_size=(128,128), 
                                    color_mode = "grayscale", batch_size=16,class_mode='categorical', subset='training')

labels = orig.class_indices
labels = dict((v,k) for k,v in labels.items())

predictions = [labels[k] for k in classes]
predictions

information = []
for landmark in predictions:
  information.append(wikipedia.summary(landmark))

information

