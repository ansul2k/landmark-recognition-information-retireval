# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f2wOhJ_5IQUVD9WYuGJEcqzUg5fVChmJ
"""

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential,Model
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D
from keras.optimizers import Adam
from keras import metrics
from keras.callbacks import ModelCheckpoint

from google.colab import drive
drive.mount('/content/drive')

# organizing photos into directories

# for root, _, files in os.walk(path):
#     current_directory_path = os.path.abspath(root)
#     label = os.path.basename(root)
#     if label != "":
#         label = label.replace("(","")
#         label = label.replace(")","")
#         label = label.replace("'","")
#         print (label)
#         if(os.path.exists('./mod_data/'+str(label))==False):
#             os.system("mkdir mod_data/"+str(label))
#         for f in files:
#             if f != ".cache":
#                 name, ext = os.path.splitext(f)
#                 current_image_path = os.path.join(current_directory_path, f)
#                 current_image = Image.open(current_image_path).convert('L')
#                 img = current_image.resize(size)
#                 img.save("mod_data/"+str(label)+"/"+name + ext)

datagen = ImageDataGenerator(validation_split=0.1,rescale=1.0/255.0)
train = datagen.flow_from_directory('/content/drive/My Drive/Project/CV Dataset/mod_data',target_size=(128,128), 
                                    color_mode = "grayscale", batch_size=16,class_mode='categorical', subset='training')
img_height,img_width = 128,128
num_classes = 220

val = datagen.flow_from_directory('/content/drive/My Drive/Project/CV Dataset/mod_data',target_size=(128, 128), 
                                  color_mode = "grayscale", batch_size=16,class_mode='categorical',subset='validation')

model = Sequential([
    Conv2D(64,3,activation='relu',input_shape=(128,128,1)),
    Conv2D(64,3,activation='relu'),
    MaxPool2D(2,strides=2),
    
    Conv2D(128,3,activation='relu'),
    Conv2D(128,3,activation='relu'),
    MaxPool2D(2,strides=2),

    Conv2D(256,3,activation='relu'),
    Conv2D(256,3,activation='relu'),
    MaxPool2D(2,strides=2),

    Conv2D(512,3,activation='relu'),
    Conv2D(512,3,activation='relu'),
    MaxPool2D(2,strides=2),
    
    Flatten(),

    Dropout(0.5),

    Dense(4096,activation='relu'),
    Dense(4096,activation='relu'),
    Dense(num_classes,activation='softmax')
    
])

tf.keras.utils.plot_model(model,to_file='/content/drive/Shared drives/Dataset/model.png',show_shapes=True)

adam = Adam(lr=0.0001)

model.compile(optimizer = adam, 
                loss='categorical_crossentropy',
                metrics=['accuracy'])

with tf.device('/device:GPU:0'):
  model.fit_generator(train,steps_per_epoch=1000, epochs=100,validation_data=val, use_multiprocessing=True)



model.save_weights('/content/drive/My Drive/Project/landmark.h5', overwrite=True)

